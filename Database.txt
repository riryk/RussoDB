
SQL Server:

To stimulate the Deadlock, let’s create two tables 
which we are going to use as an example of Deadlock.

-- Sample Table, which will track individual Orders entered by 
-- Various Sales Persons
create table Orders
(
   OrderID        int,
   OrderDate      datetime,
   Amount         money,
   SalesPersonID  int
)

-- Sample Table, which will track all individual Sales Persons details
create table SalesPerson
(
   SalesPersonID  int,
   Name           varchar(100),
   Region         varchar(100)
);


TRAN 1                                      TRAN2

begin tran                            begin tran 

update Orders                         update SalesPerson 
set SalesPersonID=4                   set Name='Li Hu Chu' 
where OrderID = 108;                  where SalesPersonID = 4; 

update SalesPerson                    update Orders 
set Region='Beijing'                  set OrderDate='2011-11-11 11:11:11.000'
where SalesPersonID = 4;              where OrderID = 108;  

commit tran                           commit tran


Transaction A attempts to update table 1 
and subsequently read/update data from table 2, 
whereas transaction B attempts to update table 2 
and subsequently read/update data from table 1. 

In such situations, transaction A holds locks 
that transaction B needs to complete its task and vice versa; 
neither transaction can complete 
until the other transaction releases locks.


Read Lock   - all readers have access to this resource.
Write Lock  - when this lock is set than no other readers and writers can read.
Update lock - only one updateLock simultaneously and can be many readers.


Intent Share     – intent shared lock. 
Intent Exclusive – intent exclusive lock. 

CREATE TABLE [dbo].[Tbl] 
(
  [X] [int] NULL,
  [Y] [int] NULL,
  [value] [varchar] (50)
)

insert into Tbl(X, Y, Value) VALUES (1, 10, 'Алма-Ата')
insert into Tbl(X, Y, Value) VALUES (2, 9, 'Алушта')
insert into Tbl(X, Y, Value) VALUES (3, 8, 'Алупка')
insert into Tbl(X, Y, Value) VALUES (4, 7, 'Анкара')


Example 1: 

 Tran1                                                        Tran2

BEGIN TRAN                                      BEGIN TRAN
  UPDATE Tbl SET X = 1 WHERE X = 1                UPDATE Tbl SET X = 3 WHERE X = 3
  UPDATE Tbl SET X = 3 WHERE X = 3                UPDATE Tbl SET X = 1 WHERE X = 1
COMMIT TRAN                                     COMMIT TRAN 

Example 2:

SET TRANSACTION ISOLATION LEVEL REPEATABLE READ

BEGIN TRAN
   SELECT @Var = Y FROM Tbl WHERE X = 2
   --- 
   --- Do something with @Var
   --- 
   UPDATE Tbl SET Y = @Var WHERE X = 2
COMMIT TRAN                                    

When execute this code in two different transactions 
we will get a deadlock.


 Tran 1                                       Tran2
 
 select 1 from Tbl where x = 2
                                       select 1 from Tbl where x = 2.
									   
 update Tbl set .... where x = 2        									 
                                       update Tbl set ... where x = 2.

									   
 When tran1 wants to acquire 
 an exclusive lock the record is being 
 read by another transaction and
 a read lock is held until the end of the transaction.
 
BEGIN TRAN

  SELECT @Var = Y FROM Tbl WITH (UPDLOCK) WHERE X = 2
  UPDATE Tbl SET Y = @Var WHERE X = 2
  
COMMIT TRAN                                    
  

Example 3:

  Tran 1                                                                Tran 2
  
SET TRANSACTION ISOLATION LEVEL READ COMMITTED          SET TRANSACTION ISOLATION LEVEL READ COMMITTED  

BEGIN TRAN                                              BEGIN TRAN     

  UPDATE Tbl SET X = 4 WHERE X = 4                      UPDATE Tbl SET X = 2 WHERE X = 2
  WAITFOR DELAY '00:00:10'
  UPDATE Tbl SET X = 6 WHERE X = 6                      COMMIT TRAN
  
COMMIT TRAN                            


The second transaction can even be:  UPDATE Tbl SET Y = 10 WHERE Y = 10



62. Bookmark Lookup.

A bookmark lookup is the process of finding 
the actual data in the SQL table, 
based on an entry found in a non-clustered index.

When you search for a value in a non-clustered index, 
and your query needs more fields 
than are part of the index leaf node 
(all the index fields, plus any possible INCLUDE columns), 
then SQL Server needs to go retrieve the actual data page(s) 
- that's what's called a bookmark lookup.

In some cases, that's really the only way to go 
- only if your query would require just one more field 
(not a whole bunch of 'em), 
it might be a good idea to INCLUDE that field in the non-clustered index. 
In that case, the leaf-level node of the non-clustered index 
would contain all fields needed to satisfy your query (a "covering" index), 
and thus a bookmark lookup wouldn't be necessary anymore.



63. Multiple indexes vs indexes on different columns?

Are there certain reasons why one should be used over the other?

Create NonClustered Index IX_IndexName On TableName
(Column1 Asc, Column2 Asc, Column3 Asc)

Versus

Create NonClustered Index IX_IndexName1 On TableName
(Column1 Asc)

Create NonClustered Index IX_IndexName2 On TableName
(Column2 Asc)

Create NonClustered Index IX_IndexName3 On TableName
(Column3 Asc)

e.g. imagine you search a table on three columns:
state, county, zip:

 - you sometimes search by state only.
 - you sometimes search by state and county.
 - you frequently search by state, county, zip.
 
Then an index with state, county, zip. 
will be used in all three of these searches.

If you search by zip alone quite a lot 
then the above index will not be used (by SQL Server anyway) 
as zip is the third part of that index 
and the query optimiser will not see that index as helpful.

You could then create an index on Zip alone 
that would be used in this instance.

SELECT * FROM tbl_name WHERE col1=val1 AND col2=val2;

If a multiple-column index exists on col1 and col2, 
the appropriate rows can be fetched directly.

If separate single-column indexes exist on col1 and col2, 
the optimizer attempts to use the Index Merge optimization
or attempts to find the most restrictive index by deciding 
which index excludes more rows and using that index to fetch the rows.


Index Merge optimization:

If your query has a complex WHERE clause with 
deep AND/OR nesting and MySQL doesn't choose the optimal plan, 
try distributing terms using the following identity laws:

(x AND y) OR z = (x OR z) AND (y OR z)
(x OR y) AND z = (x AND z) OR (y AND z)

The Index Merge intersection algorithm performs simultaneous scans 
on all used indexes and produces the intersection 
of row sequences that it receives 
from the merged index scans.


64. Database perfomance writing?


We log values and we only log them once in a table. 
When we add values to the table 
we have to do a look up everytime to see 
if it needs to insert the value or just grab the id. 

We have an index on the table (not on the primary key) 
but there are about 350,000 rows 
(so it is taking 10 seconds to do 10 of these values).


65. Avoid user defined function on large number of rows 
  – move to business layer or add new field?
  
  
66. Distinct perfomance issues?


I am performing some tests on a HSQLDB server 
with a table containing 500 000 entries. 
The table has no indices. 
There are 5000 distinct business keys. 
I need a list of them. 
Naturally I started with a DISTINCT query:


SELECT DISTINCT business_key FROM memory WHERE
   concept <> 'case' or 
   attrib <> 'status' or 
   value <> 'closed'
   
SELECT business_key FROM memory WHERE
       concept <> 'case' or 
       attrib <> 'status' or 
       value <> 'closed'
GROUP BY business_key


My guess would be that the distinct is executed like:

   Copy all business_key values to a temporary table
   Sort the temporary table
   Scan the temporary table, returning each item 
   that is different from the one before it

The group by could be executed like:

   Scan the full table, storing each value of business key in a hashtable
   Return the keys of the hashtable

   
The first method optimizes for memory usage: 
it would still perform reasonably well 
when part of the temporary table has to be swapped out. 

The second method optimizes for speed, 
but potentially requires a large amount of memory 
if there are a lot of different keys.


67. Difference between EXISTS and IN in SQL?

EXISTS will be faster because once the engine has found a hit, 
it will quit looking as the condition has proved true. 
With IN it will collect all the results 
from the subquery before further processing.

select ename from emp e
    where mgr in 
	 (select empno 
	  from emp 
	  where ename = 'KING');
	
This query is virtually equivalent to this:

select e1.ename 
from emp e1,
(select empno from emp where ename = 'KING') e2
where e1.mgr = e2.empno;	

You can write the same query using EXISTS 
by moving the outer query column 
to a subquery condition, like this:

select ename from emp e
    where exists 
	  (select 0 
	   from emp 
	   where e.mgr = empno and ename = 'KING');

When you write EXISTS in a where clause, 
you're telling the optimizer 
that you want the outer query to be run first, 
using each value to fetch a value 
from the inner query (think: EXISTS = outside to inside).	

set serveroutput on;
declare
    l_count integer;
begin
    for e in (select mgr,ename from emp) loop
        select count(*) into l_count from emp
         where e.mgr = empno and ename = 'KING';
        if l_count != 0 then
            dbms_output.put_line(e.ename);
        end if;
    end loop;
end;


68. Difference between EXISTS and IN in SQL?

declare @tmp table (Col1 int, Col2 int);
create table #tmp (Col1 int, Col2 int);

As a rule of thumb, for small to medium volumes of data 
and simple usage scenarios you should use table variables. 
(This is an overly broad guideline with of course lots of exceptions 
- see below and following articles.)

Temporary Tables are real tables so you can do things like CREATE INDEXes, etc. 
If you have large amounts of data for which accessing by index 
will be faster then temporary tables are a good option.

Table variables don't participate in transactions, logging or locking. 
This means they're faster as they don't require the overhead, 
but conversely you don't get those features. 

You can pass table variables back from functions, 
enabling you to encapsulate and reuse logic much easier 
(eg make a function to split a string into a table of values on some arbitrary delimiter).

 "Temporary table" :

 The name "temporary" is slightly misleading, 
 for even though the tables are instantiated in tempdb, 
 they are backed by physical disk 
 and are even logged into the transaction log. 
 
Furthermore, the scope of any particular temporary table 
is the session in which it is created; 
meaning it is only visible to the current user.  
Multiple users could create a temp table named #TableX 
and any queries run simultaneously would not affect one another 
- they would remain autonomous transactions 
and the tables would remain autonomous objects. 

You can create indexes and statistics on temporary tables.  
You can also apply Data Definition Language (DDL) statements 
against temporary tables to add constraints, defaults, 
and referential integrity such as primary and foreign keys. 

 "Table variables" :
 
Table variables can not have Non-Clustered Indexes.
You can not create constraints in table variables.
You can not create default values on table variable columns.

1. Local Temp Table

Local temp tables are only available to the SQL Server session 
or connection (means single user) that created the tables. 
These are automatically deleted 
when the session that created the tables has been closed.

2. Global Temp Table

Global temp tables are available to all SQL Server sessions or connections (means all the user). 
These can be created by any SQL Server connection user 
and these are automatically deleted 
when all the SQL Server connections have been closed.

This acts like a variable and exists for a particular batch of query execution. 
It gets dropped once it comes out of batch. 
This is also created in the Tempdb database but not the memory. 
This also allows you to create primary key, 
identity at the time of Table variable declaration 
but not non-clustered index.

The transaction semantics for table variables is different from temporary tables. 
Table variables are not affected by transaction rollbacks. 
Every operation on a table variable is committed immediately in a separate transaction.

Temporary tables can also be referenced in nested stored procedures 
and may be the right fit if the object needs to be available for a longer duration 
(not just scoped to the batch like table variables).

Both temporary tables and table variables are kept in memory 
until their size reaches a certain threshold 
after which they are pushed to disk.

There are no statistics based recompiles for table variables.
The general rule of thumb is to use temporary tables 
when operating on large datasets 
and table variables for small datasets with frequent updates. 

create procedure table_variable_proc
as
begin

      declare @table_variable 
	            table
				(
				  col1      int, 
				  col2      varchar(128)
				);
				
      declare @i int;
      set     @i = 0;
	  
      while (@i < 100000)
      begin
          insert into @table_variable 
		  values(@i, convert(varchar(128), @i));
			 
          set @i = @i + 1;
      end
	  
      select * from @table_variable tv 
	  join test_table 
	  on tv.col1 = test_table.col1;
end

create procedure temp_table_proc
as
begin

      create table #table_name
	  (
	      col1    int, 
		  col2    varchar(128)
	  );
	  
      declare @i int;
      set     @i = 0;
	  
      while (@i < 100000)
      begin
          insert into #table_name 
		  values(@i, convert(varchar(128), @i));
		  
          set @i = @i + 1;
      end
	  
      select * from #table_name 
	  join test_table 
	  on #table_name.col1 = test_table.col1;
end


Notice that the query plan for the table variables query 
estimates 1 row at compile time 
and therefore chooses a nested loop join. 

In the temporary tables case, however, the query plan chosen 
is a hash join which leads to better query performance. 
Since the query plan for table variables always estimates 
the number of rows at compile time to be zero or one, 
table variables may be more suitable when operating on smaller datasets. 

When the stored procedure DemoProc1 is compiled, 
the insert and select query are not compiled. 
This is because during initial compilation, 
the temporary table does not exist 
and the compilation of this query is deferred until execution time. 
A compiled plan for the stored procedure is generated, but is incomplete. 
At execution time, the temporary table is created, 
and the select and insert statement are compiled. 
Since the stored procedure is already in execution, 
this compilation of the select and insert query are classified as a recompilation.

















