
1. CLR Hosting


When developing the CLR, Microsoft implemented it as a COM server contained inside a DLL;
that is, Microsoft defined a standard COM interface for the CLR and assigned GUIDs to this interface
and the COM server. When you install the .NET Framework, the COM server representing the CLR is
registered in the Windows registry just as any other COM server would. If you want more information
about this topic, refer to the MetaHost.h C++ header file that ships with the .NET Framework SDK.
This header file defines the GUIDs and the unmanaged ICLRMetaHost interface definition.

2. What happens when a managed executable starts.

By default, when a managed executable starts, the shim examines the executable file and extracts
the information indicating the version of the CLR that the application was built and tested
with.
Initialize and start the CLR.
Load an assembly and execute code in it.

3. How does Windows know that a binary is a .NET application?

Normally .exe files are executed by Windows by looking at the PE-Header. 
This PE-Header says how it should be loaded into memory, 
what dependencies it has, and where the entry point is.

4. Where is the entry-point of a .NET application?

Well, your application is in some IL-code. 
Executing that directly will clearly lead to a crash. 
It is not the IL-code that should start executing, 
but the .NET runtime, which eventually should load the IL-code and execute it.

In newer versions of Windows, .NET comes preinstalled, 
and Windows has built-in support for recognizing a .NET application. 
This can be done by simply looking in the PE-Header present in all executables and DLLs. 
In older versions of Windows, execution is passed to an entry point 
where boot-strapper code is located. 

The boot-strapper, which is native code, uses an unmanaged CLR Hosting API, 
to start the .NET runtime inside the current process 
and launch the real program which is the IL-code.

5. Hosting the CLR in an unmanaged app

When you start the .NET runtime inside a native process, 
that native application becomes a host for the runtime. 
This lets you add .NET capabilities to your native applications.

#include <metahost.h>
#include <mscoree.h>
#pragma comment(lib, "mscoree.lib")

ICLRMetaHost    *pMetaHost     = nullptr;
ICLRRuntimeHost *pRuntimeHost  = nullptr;
ICLRRuntimeInfo *pRuntimeInfo  = nullptr;
HRESULT hr;

hr = CLRCreateInstance(CLSID_CLRMetaHost, IID_ICLRMetaHost, (LPVOID*)&pMetaHost);
hr = pMetaHost->GetRuntime(runtimeVersion, IID_PPV_ARGS(&pRuntimeInfo));
hr = pRuntimeInfo->GetInterface(CLSID_CLRRuntimeHost,IID_PPV_ARGS(&pRuntimeHost));
hr = pRuntimeHost->Start();

_AppDomain* pCurrentDomain = nullptr;
hr = pRuntimeHost->GetDefaultDomain(&pCurrentDomain);
pCurrentDomain.ExecuteAssembly(assemblyFilename);


Now the runtime is running, but it hasn't got any loaded user code yet. 
Some internal thread scheduler and garbage collector are surely running, 
because they are part of the CLR runtime.


To be able to register a new AppDomainManager, 
we will need an interface called ICLRControl. 
This interface contains a method SetAppDomainManagerType, 
which loads your managed implementation of the AppDomainManager.


ICLRControl* pCLRControl = nullptr;
hr = pRuntimeHost->GetCLRControl(&pCLRControl);
LPCWSTR assemblyName = L"SampleAppDomainManager";
LPCWSTR appDomainManagerTypename = L"SampleAppDomainManager.CustomAppDomainManager";
hr = pCLRControl->SetAppDomainManagerType(assemblyName, appDomainManagerTypename);


[GuidAttribute("0C19678A-CE6C-487B-AD36-0A8B7D7CC035"), ComVisible(true)]
public sealed class CustomAppDomainManager : AppDomainManager, ICustomAppDomainManager
{
  public CustomAppDomainManager()
  {
     System.Console.WriteLine("*** Instantiated CustomAppDomainManager");
  }

  public override void InitializeNewDomain(AppDomainSetup appDomainInfo)
  {
     System.Console.WriteLine("*** InitializeNewDomain");
     this.InitializationFlags = AppDomainManagerInitializationOptions.RegisterWithHost;
  }

  public override AppDomain CreateDomain(string friendlyName,
          Evidence securityInfo, AppDomainSetup appDomainInfo)
  {
     var appDomain = base.CreateDomain(friendlyName, securityInfo, appDomainInfo);
     System.Console.WriteLine("*** Created AppDomain {0}", friendlyName);
     return appDomain;
  }
}

Before any managed code can be executed, 
the host must load and initialize the common language runtime.
All hosts start with an unmanaged stub because the runtime is not yet running in the process.

After loading and initializing the common language runtime, 
the host must make the transition from unmanaged to managed code 
in order to execute managed hosting code and user code.

After a host has determined where domain boundaries lie, 
based on the criteria described in the previous section, 
the host uses the CreateDomain method of the System.AppDomain type 
to create domains in which to run user code. 
Each application domain contains a collection of name/value pairs 
in which a host can store information about a domain. 
The name/value pairs are passed as a parameter to CreateDomain.


6. AppDomains.


When the CLR COM server initializes, it creates an AppDomain. An AppDomain is a logical container
for a set of assemblies. The first AppDomain created when the CLR is initialized is called the default
AppDomain; this AppDomain is destroyed only when the Windows process terminates.

In addition to the default AppDomain, a host using either unmanaged COM interface methods or
managed type methods can instruct the CLR to create additional AppDomains. The whole purpose of
an AppDomain is to provide isolation. Here are the specific features offered by an AppDomain:

- Objects created by code in one AppDomain cannot be accessed directly by code in another

AppDomain When code in an AppDomain creates an object, that object is “owned”
by that AppDomain. In other words, the object is not allowed to live beyond the lifetime of
the AppDomain whose code constructed it. Code in other AppDomains can access another
AppDomain’s object only by using marshal-by-reference or marshal-by-value semantics. This
enforces a clean separation and boundary because code in one AppDomain can’t have a
direct reference to an object created by code in a different AppDomain.

-AppDomains can be unloaded The CLR doesn’t support the ability to unload a single assembly

from an AppDomain. However, you can tell the CLR to unload an AppDomain, which
will cause all of the assemblies currently contained in it to be unloaded as well.

-AppDomains can be individually secured 
When created, an AppDomain can have a permission
set applied to it that determines the maximum rights granted to assemblies running
in the AppDomain. This allows a host to load some code and be ensured that the code cannot
corrupt or read important data structures used by the host itself.

Important A great feature of Windows is that it runs each application in its own process
address space. This ensures that code in one application cannot access code or data in use
by another application. Process isolation prevents security holes, data corruption, and other
unpredictable behaviors from occurring, making Windows and the applications running
on it robust. Unfortunately, creating processes in Windows is very expensive. The Win32
CreateProcess function is very slow, and Windows requires a lot of memory to virtualize
a process’s address space.

However, if an application consists entirely of managed code that is verifiably safe and
doesn’t call out into unmanaged code, there are no problems related to running multiple
managed applications in a single Windows process. And AppDomains provide the isolation
required to secure, configure, and terminate each of these applications.

each type object
in the loader heap has a method table, and each entry in the method table points to JIT-compiled native
code if the method has been executed at least once.

Furthermore, as code in an AppDomain calls methods defined by a type, the method’s
Intermediate Language (IL) code is JIT-compiled, and the resulting native code is associated with each
AppDomain;

Some assemblies are expected to be used by several AppDomains. MSCorLib.dll is the best example.
This assembly contains System.Object, System.Int32, and all of the other types that are so
integral to the .NET Framework. This assembly is automatically loaded when the CLR initializes, and all
AppDomains share the types in this assembly. To reduce resource usage, MSCorLib.dll is loaded in an
AppDomain-neutral fashion;



7. Accessing Objects Across AppDomain Boundaries.

Marshal by reference communication between two different domains.

{
   AppDomain adCallingThreadDomain = Thread.GetDomain();
   String exeAssembly = Assembly.GetEntryAssembly().FullName;
   
   AppDomain ad2 = AppDomain.CreateDomain("AD #2", null, null);
   mbrt = (MarshalByRefType)ad2.CreateInstanceAndUnwrap(exeAssembly, "MarshalByRefType");
   
   // Prove that we got a reference to a proxy object
   Console.WriteLine("Is proxy={0}", RemotingServices.IsTransparentProxy(mbrt));

   // This looks like we're calling a method on MarshalByRefType but we're not.
   // We're calling a method on the proxy type. The proxy transitions the thread
   // to the AppDomain owning the object and calls this method on the real object.
   mbrt.SomeMethod();
}


However, a one-to-one
correspondence doesn’t exist between threads and AppDomains. AppDomains are a CLR feature;
Windows knows nothing about AppDomains. Because multiple AppDomains can be in a single
Windows process, a thread can execute code in one AppDomain and then execute code in another
AppDomain. From the CLR’s perspective, a thread is executing code in one AppDomain at a time.


The new AppDomain
will have its very own loader heap, which will be empty because there are currently no assemblies
loading into the new AppDomain. When you create an AppDomain, the CLR does not create any
threads in this AppDomain; no code runs in the AppDomain unless you explicitly have a thread call
code in the AppDomain.

When a source AppDomain wants to send or return the reference of an object to a destination
AppDomain, the CLR defines a proxy type in the destination AppDomain’s loader heap. This proxy
type is defined using the original type’s metadata, and therefore, it looks exactly like the original type;
it has all of the same instance members (properties, events, and methods).

8. Domain unloading.

One of the great features of AppDomains is that you can unload them. Unloading an AppDomain
causes the CLR to unload all of the assemblies in the AppDomain, and the CLR frees the AppDomain’s
loader heap as well.

- The CLR suspends all threads in the process that have ever executed managed code.
- The CLR forces any threads that have the unloading
  AppDomain on their stack to throw a ThreadAbortException 
  (resuming the thread’s execution).

1. 

This causes the threads to unwind, 
executing any finally blocks on their way out so
that cleanup code executes.

This causes the threads to unwind, executing any finally blocks on their way out so
that cleanup code executes.

If no code catches the ThreadAbortException, it will eventually
become an unhandled exception that the CLR swallows;

the thread dies, but the process is allowed to continue running. 
This is unusual, because for all other unhandled exceptions, the
CLR kills the process.

An aborting thread is
allowed to finish executing these code blocks and then, at the end of the code
block, the CLR forces the thread to throw a ThreadAbortException.


2. 
After all threads discovered in step 2 have left the AppDomain, the CLR then walks the heap
and sets a flag in each proxy object that referred to an object created by the unloaded AppDomain.
These proxy objects now know that the real object they referred to is gone. If any
code now calls a method on an invalid proxy object, the method will throw an AppDomainUnloadedException.

3. 
The CLR forces a garbage collection to occur, reclaiming the memory used by any objects that
were created by the now unloaded AppDomain. The Finalize methods for these objects are
called, giving the objects a chance to clean themselves up properly.

4.
The CLR resumes all of the remaining threads. The thread that called AppDomain.Unload will
now continue running; calls to AppDomain.Unload occur synchronously.

5. 
The CLR forces a garbage collection to occur, reclaiming the memory used by any objects that
were created by the now unloaded AppDomain. The Finalize methods for these objects are
called, giving the objects a chance to clean themselves up properly.

6.
The CLR resumes all of the remaining threads. The thread that called AppDomain.Unload will
now continue running; calls to AppDomain.Unload occur synchronously.


When Windows initializes a process by using a managed EXE file, Windows loads the shim,
and the shim examines the CLR header information contained in the application’s assembly 
(the EXE file).


9. Executable application.

When Windows initializes a process by using a managed EXE file, Windows loads the shim,
and the shim examines the CLR header information contained in the application’s assembly 
(the EXE file). 

The header information indicates the version of the CLR 
that was used to build and test the application. 

The shim uses this information to determine which version of the CLR to load into the
process. After the CLR loads and initializes, it again examines the assembly’s CLR header to determine
which method is the application’s entry point (Main). The CLR invokes this method, and the application
is now up and running.

releases all of the unmanaged COM objects held by the CLR.


10. How does Silverlight launch CLR?

1. Loads the Silverlight CLR (CoreClr.dll) in your browser.
2. Each Silverlight control on the page runs in its own AppDomain.
3. When the user closes a tab or navigates to another website, 
   any Silverlight controls no longer in use have their AppDomains unloaded.

11. How does ASP.NET and XML Web Services Applications?

ASP.NET is implemented as an ISAPI DLL (implemented in ASPNet_ISAPI.dll).
The first time a client requests a URL handled 
by the ASP.NET ISAPI DLL, ASP.NET loads the CLR.

If it is, ASP.NET tells the CLR to create a new AppDomain for this web application;

ASP.NET then tells the CLR to load the assembly that contains
the type exposed by the web application into this new AppDomain, creates an instance of this type,
and starts calling methods in it to satisfy the client’s web request.

The methods will already be JIT-compiled into native code,
so the performance of processing all subsequent client requests is excellent.

If a client makes a request of a different web application, 
ASP.NET tells the CLR to create a new AppDomain.

This new AppDomain is typically created inside the same worker process as the other
AppDomains.


12. How does Microsoft SQL Server launch CLR?

13. What does the CLR host do when the thread is running for a long period 
of time and we need to stop it?

When the host originally received the client’s request, it recorded the time. If the untrusted
code doesn’t respond to the client in some administrator-set amount of time, the host calls
Thread’s Abort method, asking the CLR to stop the thread pool thread, forcing it to throw a
ThreadAbortException.

14. What is the process of C# code compilation?
 - Then you use the corresponding compiler to check the syntax and analyze the source code.
 - Builds the C# code into managed module.

A managed module is a standard 32-bit Windows portable
executable (PE32) file or a standard 64-bit Windows portable executable (PE32+) 
file that requires the CLR to execute.

Extentions that have been made for .NET metadata.
CLR sections:

1. The standard Windows PE file header, which is similar to the Common Object File Format
   (COFF) header. This header also indicates the type of file: GUI, CUI, or DLL, and
   contains a time stamp indicating when the file was built. For modules that contain
   native CPU code, this header contains information about the native CPU code.
   
2. CLR Header.
   Contains the information 
   (interpreted by the CLR and utilities) that makes this a managed
   module. The header includes the version of the CLR required.
   
3. Metadata section. Exported types. 
   Every managed module contains metadata tables. There are two main types of tables:
   tables that describe the types and members defined in your source code and tables that
   describe the types and members referenced by your source code.   
   In addition, metadata also has tables indicating what the
   managed module references, such as imported types and their members.
   Metadata is a superset of older technologies such 
   as COM’s Type Libraries and Interface Definition Language (IDL) files. 
   The important thing to note is that CLR metadata is far more complete.
   And, unlike Type Libraries and IDL, metadata is always associated with the file 
   that contains the IL code. 
   In fact, the metadata is always embedded in the same EXE/DLL as the code, 
   making it impossible to separate the two
   

4. Intermediate Language (IL).  Common intermediate Language .NET CLR. 
   Code the compiler produced as it compiled the source code. 
   At run time, the CLR compiles the IL into native CPU instructions.
   

15. What are benefits from Metadata?

- Compilers can read metadata directly from managed modules.
- Microsoft Visual Studio uses metadata to help you write code. 
  Its IntelliSense feature parses metadata to tell you 
  what methods, properties, events, and fields a type offers.
- The CLR’s code verification process uses metadata to ensure 
  that your code performs only “type-safe” operations.
- Metadata allows an object’s fields to be serialized into a memory block.
- Metadata allows the garbage collector to track the lifetime of objects. 
  For any object, the garbage collector can determine the type of the object 
  and, from the metadata, know which fields within that object refer to other objects.

  ###############################################################
  
16. How is IL code converted to CPU native code?

To execute a method, its IL must first be converted to native CPU instructions. 
This is the job of the CLR’s JIT (just-in-time) compiler.

When Main makes its first call to WriteLine, the JITCompiler function is called. The JITCompiler
function is responsible for compiling a method’s IL code into native CPU instructions.

JITCompiler

1. In the assembly that implements the type(Console), 
   look up the method (WriteLine) being called in the metadata.
2. From the metadata, get the IL for this method.
3. Allocate a block of memory.
4. Compile the IL into native CPU instructions;
   the native code is saved in the memory allocated in step 3.
5. Modify the method’s entry in the Type’s table so that 
   it now points to the memory block allocated in step 3.
6. Jump to the native code contained inside the memory block.

Main now calls WriteLine a second time. This time, the code for WriteLine has already been
verified and compiled. So the call goes directly to the block of memory, skipping the JITCompiler
function entirely.

A performance hit is incurred only the first time a method is called. All subsequent calls to the
method execute at the full speed of the native code because verification and compilation to native
code don’t need to be performed again.

The JIT compiler stores the native CPU instructions in dynamic memory. This means that the compiled
code is discarded when the application terminates. So if you run the application again in the
future or if you run two instances of the application simultaneously (in two different operating system
processes), the JIT compiler will have to compile the IL to native instructions again.

###############################################################

17. When managed code compilation can overperform unmanaged code?

- A JIT compiler can determine if the application is running on an Intel Pentium 4 CPU and produce
  native code that takes advantage of any special instructions offered by the Pentium 4.
  Usually, unmanaged applications are compiled for the lowest-common-denominator CPU and
  avoid using special instructions that would give the application a performance boost.
  
- A JIT compiler can determine when a certain test is always false 
  on the machine that it is running on.

- The CLR could profile the code’s execution and recompile the IL into native code 
  while the application runs.

###############################################################  
 
18. What does NGen.exe do?

This tool compiles all of an assembly’s IL code into native code and saves the
resulting native code to a file on disk. At run time, when an assembly is loaded, the CLR automatically
checks to see whether a precompiled version of the assembly also exists, and if it does, the CLR loads
the precompiled code so that no compilation is required at run time.

###############################################################

19. What does CLR verification do?

- Verification examines the high-level IL code and
  ensures that everything the code does is safe.
  
- Verification checks that every method is
  called with the correct number of parameters,
  
- that each parameter passed to every method is of the correct type, 

- that every method’s return value is used properly, 
  that every method has a return statement, and so on.

  ###############################################################
  
20. Benefits from CLR?

Because Windows processes require a lot of operating system resources, having many of them
can hurt performance and limit available resources. 
Reducing the number of processes by running multiple applications in a single operating system process 
can improve performance, require fewer resources, 
and be just as robust as if each application had its own process. 
This is another benefit of
managed code as compared to unmanaged code.

###############################################################

21. What is "The Common Type System".

###############################################################

22. What are two kinds of assemblies?

Strongly assembly type: 

strongly named assembly is signed with a publisher’s public/private key pair 
that uniquely identifies the assembly’s publisher.
This key pair allows the assembly to be uniquely identified, secured, and
versioned, and it allows the assembly to be deployed anywhere on the user’s machine or even on the
Internet.

However, we have a problem: Two (or more) companies could produce assemblies
that have the same file name. Then, if both of these assemblies get copied into the same well-known
directory, the last one installed wins, and all of the applications that were using the old assembly no
longer function as desired.

A strongly named assembly consists of four attributes that uniquely identify the assembly: 
a file name (without an extension), a version number, a culture identity, and a public key.

"MyTypes, Version=1.0.8123.0, Culture=neutral, PublicKeyToken=b77a5c561934e089"

###############################################################

23. How to create a strongly named assembly?

- is to obtain a key by using the Strong Name utility, SN.exe, 
  that ships with the .NET Framework SDK and Microsoft Visual Studio.
  
  Command "SN –k MyCompany.snk" generates a public/private key pair.

- generate a public key token. 
  A public key token is a 64-bit hash of the public key. 
  SN.exe’s –tp switch shows the public key token 
  that corresponds to the complete public key at the end of its output.
  
- Compile the assembly with this key.

###############################################################

24. What are benefits from strongly named assemblies?

Signing an assembly with a private key and embedding the signature and public key within an assembly
allows the CLR to verify that the assembly has not been modified or corrupted. When an
assembly is installed into the GAC, the system hashes the contents of the file containing the manifest
and compares the hash value with the RSA digital signature value embedded within the PE file (after
unsigning it with the public key).


25. How are new resources allocated?

- Initializing the managed heap.
  The CLR also maintains a pointer, which I’ll call NextObjPtr. 
  This pointer indicates where the next object is to be allocated within the heap. 
  Initially, NextObjPtr is set to the base address of the address space region.
  
- Calculate the number of bytes required for the type’s fields 
  (and all the fields it inherits from its base types).
  
- Allocates memory from NextObjPtr and zeros it 
  and after that moves a pointer further.
  
26. What is the Garbage collection algorithm?

When there are not enough free memory. CLR performs a Garbage Collection.
Reference counting. Each object increases reference count when it acquires it
and starts processing it. When the object is not longer needed it's reference
count is decremented.

When we have circular references this algorithm does not work.
Instead of it we use reference tracking algorithm.

From the start:
1. Suspend all threads in the process.
2. The marking phrase of GC.

First, it walks through all the objects in the heap
setting a bit (contained in the sync block index field) to 0. 
This indicates that all objects should be deleted. 
Then, the CLR looks at all active roots to see which objects they refer to. 
This is what makes the CLR’s GC a reference tracking GC. 
If a root contains null, the CLR ignores the root 
and moves on to examine the next root.


27. How does the GC treat cycle references?

1. Start.

It starts from active roots. 
If a root does not have descendants it is skipped.
Otherwise we loop through all descendants and mark them as undeleted.
Then we process all descendants of these descendants and skip those 
nodes that have already been marked. In this way we avoid an infinite loop.


Once complete, the heap contains some marked and some unmarked objects. 
The marked objects must survive the collection because 
there is at least one root that refers to the object;

All slots of memory which are marked with 0 will be deleted.

2. GC’s compacting phase.

During the compacting phase, the CLR shifts the memory consumed
by the marked objects down in the heap, compacting all the surviving objects 
together so that they are contiguous in memory.

Reducing your application’s working set size,
thereby improving the performance of accessing these objects in the future.

Second, the free space is all contiguous as well, 
so this region of address space can be freed, 
allowing other things to use it.

Because some objects have been shifted in memory to other addresses.
That's why their descendant objects now point 
to an invalid or corrupted addresses of memory.
We should loop through them and change addresses to correct ones. 

3. Change NextObjPtr to a new free memory position.
4. Resume all suspended threads.


28. What do generations mean?

Generational garbage collection makes the following assumptions:
- The newer an object is, the shorter its lifetime will be.
- The older an object is, the longer its lifetime will be.
- Collecting a portion of the heap is faster than collecting the whole heap.

Generation 0:

When initialized, the managed heap contains no objects. Objects added to the heap are said to be
in generation 0. Stated simply, objects in generation 0 are newly constructed objects that the garbage
collector has never examined.

 -------------------------------------------------
| A | B | C | D | E |                             |
 -------------------------------------------------
|-------------------> 
  Generation 0
  
When the CLR initializes, it selects a budget size (in kilobytes) for generation 0. So if allocating a
new object causes generation 0 to surpass its budget, a garbage collection must start. Let’s say that
objects A through E fill all of generation 0. When object F is allocated, a garbage collection must start.

Start garbage collection and scan all objects in memory.
And if turns out that A,B,D are still referenced and 
objects C,E are not already referenced and we can delete them.
Garbage collector deletes them and shifts existed objects to 
make them adjacent.

 -------------------------------------------------
| A | B | D |                         |           |
 -------------------------------------------------
|----------> ------------------------>
Generation 1     Generation 0
  
The objects that survived one garbage collection 
are marked as generation 1.

Than we allocate new objects to generation 1:


 -------------------------------------------------
| A | B | D |  F  | G | H | I | J | K |           |
 -------------------------------------------------
|----------> ------------------------>
Generation 1     Generation 0

B,H,J  became unreachable and need to be reclaimed

If generation 0 exceeds its budget we need to run a garbage 
collection and we take only objects from generation 0.
We skip generation 1.

The first assumption is that newly created objects have a short lifetime.
So generation 0 is likely to have a lot of garbage in it, 
and collecting generation 0 will therefore reclaim a lot of memory.

If a root or an object refers to an object in an old generation, the garbage
collector can ignore any of the older objects’ inner references, decreasing the amount of time
required to build the graph of reachable objects.

29. What does finalization mean?

Finalization allows an object to execute some code after 
the object has been determined to be garbage but before
the object’s memory is reclaimed from the managed heap.
 
System.Object, the base class of everything, defines a protected 
and virtual method called Finalize.
When the garbage collector determines that an object is garbage, 
it calls the object’s Finalize method (if it is overridden).

Furthermore, be aware of the fact that you have 
no control over when the Finalize method will execute.
Finalize methods run when a garbage collection occurs, 
which may happen when your application requests more memory.

30. What is GC.SuppressFinalize()?

SuppresFinalize should only be called by a class that has a finalizer. 
It's informing the GC that this object was cleaned up fully.
The recommended IDisposable pattern when you have a finalizer is....

public class MyClass : IDisposable
{
    private bool disposed = false;

    protected virtual void Dispose(bool disposing)
    {
        if (!disposed)
        {
            if (disposing)
            {
                // called via myClass.Dispose(). 
                // OK to use any private object references
            }

            disposed = true;
        }
    }

    public void Dispose() // Implement IDisposable
    {
        Dispose(true);
        GC.SuppressFinalize(this);
    }

    ~MyClass() // the finalizer
    {
        Dispose(false);
    }
}

31. How does IDisposable work?

// Create the temporary file.
using (FileStream fs = new FileStream("Temp.dat", FileMode.Create)) 
{
   // Write the bytes to the temporary file.
   fs.Write(bytesToWrite, 0, bytesToWrite.Length);
}

Then you access the variable via code contained inside using’s braces. 
When you compile this code, the compiler automatically emits the try and finally blocks. 
Inside the finally block, the compiler emits code to cast the object 
to an IDisposable and calls the Dispose method.

// Create the temporary file.
FileStream fs = new FileStream("Temp.dat", FileMode.Create);
try 
{
   // Write the bytes to the temporary file.
   fs.Write(bytesToWrite, 0, bytesToWrite.Length);
}
finally 
{
   // Explicitly close the file when finished writing to it.
   if (fs != null) fs.Dispose();
}

FileStream   fs = new FileStream("DataFile.dat", FileMode.Create);
StreamWriter sw = new StreamWriter(fs);
sw.Write("Hi there");
// The following call to Dispose is what you should do.
sw.Dispose();
// NOTE: StreamWriter.Dispose closes the FileStream;
// the FileStream doesn't have to be explicitly closed.

What do you think would happen if there were no code to explicitly call Dispose? 

Well, at some point, the garbage collector would correctly detect 
that the objects were garbage and finalize them. 
But the garbage collector doesn’t guarantee the order 
in which objects are finalized. 
So if the FileStream object were finalized first, it would close the file. 
Then when the StreamWriter object was finalized, 
it would attempt to write data to the closed file, throwing an exception. 
If, on the other hand, the StreamWriter object were finalized first, 
the data would be safely written to the file.


32. How does finalization work?

- Application creates a new object.
  The new operator allocates the memory from the heap.
  If the object’s type defines a Finalize method, 
  a pointer to the object is placed on the finalization list  
  
- Scan. When the garbage collector finds an object and 
  finds it in the finalization list it adds it to 
  F-reachable queue.
  
- A special high-priority CLR thread is dedicated to calling Finalize methods. 
  A dedicated thread is used to avoid potential thread synchronization situations 
  that could arise if one of the application’s normal-priority threads were used instead.
  When the freachable queue is empty (the usual case), this
  thread sleeps. But when entries appear, this thread wakes, removes each entry from the queue, and
  then calls each object’s Finalize method.
  When the freachable queue is empty (the usual case), this thread sleeps. 
  But when entries appear, this thread wakes, removes each entry from the queue, 
  and then calls each object’s Finalize method.
  
  The garbage collector compacts the reclaimable memory, 
  which promotes the resurrected object to an older generation (not ideal). 
  And now, the special finalization thread empties the freachable queue, 
  executing each object’s Finalize method.

  The important point to get from all of this is 
  that two garbage collections are required to reclaim memory 
  used by objects that require finalization.
  
33. How does weak references work?

  When a root points to an object, the object cannot be collected 
  because the application's code can reach the object. 
  When a root points to an object, it's called a strong reference to the object. 
  However, the garbage collector also supports weak references. 
  Weak references allow the garbage collector to collect the object, 
  but they also allow the application to access the object.
  
  Void Method() 
  {
      // Creates a strong reference to the
      // object.
      Object o = new Object();    

      // Create a strong reference to a short WeakReference object.
      // The WeakReference object tracks the Object.
      WeakReference wr = new WeakReference(o);

      o = null;    // Remove the strong reference to the object

      o = wr.Target;
      if (o == null) 
	  {
          // A GC occurred and Object was reclaimed.
      } 
	  else 
	  {
          // a GC did not occur and we can successfully access the Object 
          // using o
      }
  }

  When the user switches away from the first part of the application, 
  you can create a weak reference to the tree and destroy all strong references. 
  If the memory load is low for the other part of the application, 
  then the garbage collector will not reclaim the tree's objects. 
  
  When the user switches back to the first part of the application, 
  the application attempts to obtain a strong reference for the tree. 
  If successful, the application doesn't have to traverse the user's hard drive again.
  
  WeakReference(Object target, Boolean trackResurrection); 
  
  The trackResurrection parameter indicates whether the WeakReference object 
  should track the object after it has had its Finalize method called.
  
  How to use weak references?
  For example if we have read a very large object into memory, object 
  that contains information about all drives, folders and files.
  We obtain a strong reference:
  
  Object obj = new Object(); 
  
  Then we use it for some small period of time and switch over
  to another window. And we do not want to waste memory.
  So that we transform our strong reference to weak reference:
  
  WeakReference wr = new WeakReference(obj);
  
  It means that this object is available for garbage collection
  and if garbage collection occurs it will reclaim this memory.
  But if the application uses memory seldom so that garbage collection
  occurs rarely as well and this memory won't be deleted with large possibility.
  But if switch back to the original window, 
  we should return a reference to the tree.
  
  obj = wr.Targtet;
  
  if wr.Target is null, it means that garbage collection has already occured.
  
  if (wr.Target == null)
     we should load the object from the file system.
   
  The managed heap contains two internal data structures 
  whose sole purpose is to manage weak references: 
  the short weak reference table and the long weak reference table. 
  These two tables simply contain pointers to objects allocated within the managed heap. 
  
  Weak references inside:
  
  We switch over to another window and suppose we have run out whole memory.
  Garbage collection is started:
  1. It builds a graph of reachable objects.
  2. It scans short weak reference table and finds one object.
     If this object is not part of the graph it is considered unreachable
	 and will be freed and then sets the weak reference to null.
  
 
34. Examples of memory leak in .NET?

- Memory leak with delegates:

private delegate void MessageWriter(string text);

public class ConsoleWriter
{
   public void WriteToConsole(string text)
   {
      Console.Write(text);
   }
}

// Client code...
ConsoleWriter writerObj = new ConsoleWriter();
MessageWriter writerDel = new MessageWriter(writerObj.WriteToConsole);

writerDel("Hello, World!");
                                        ------------
 ------------     ------------------>  | writerObj  |
| writerDel  |   | strong reference     ------------
|------------|   | 
| target     |---                      -------------
| method     |----------------------> | writerDel   |
 ------------                          -------------
 
 For example if we have have a and do the event subscription here.
 
 public class EventListener
 {
     StateObject  _obj;
 
     public EventListener(StateObject obj)
	 {
	     _obj = obj;
         _obj.SomeEvent += new EventHandler();		 
	 }
	 
	 public void SomeMethod(object sender, EventArgs args)
	 {
	     // Do some work here 
	 }
 }
 
 public class StateObject
 {
     public event SomeEvent;
 }
 
 
 public class Program
 {
     public void Main()
	 {
	     var state1 = new StateObject();
	     var event1 = new EventListener();
		 event1 = null;
		 
		 // Call garbage collection here.
		 // It should be deleted. But 
		 GC.Collect();
		 
		 // But after memory collection event1 should be deleted.
		 // But ii won't be deleted. state1 contains reference to it.
	 }
 }
 
 We can solve it by applying weak references.
                  
- Memory leak with static events.
				  
static event EventHandler Evil;

for(int i = 0 ; i < 1000000 ; i++)
    Evil += delegate {};

	
35. When do we need to create a new thread?

You need the thread to run with a non-normal thread priority. 
All thread pool threads run at normal priority. 
Although you can change this, it is not recommended, 
and the priority change does not persist across thread pool operations.

You want to start a thread and possibly abort 
it prematurely by calling Thread’s Abort method.

At this point, the thread is executing code 
and manipulating data in its process’s address space.
After another time-slice, Windows performs another context switch. 
Windows performs context switches from the moment the system 
is booted and continues until the system is shut down.

For example, if a priority 5 thread is running and the system determines 
that a higher-priority thread is ready to run, 
the system immediately suspends the lower-priority thread
(even if it’s in the middle of its time-slice) 
and assigns the CPU to the higher-priority thread, 
which gets a full time-slice.

36. What is CLR thread pool?

To improve
this situation, the CLR contains code to manage its own thread pool. You can think of a thread
pool as being a set of threads that are available for your application’s own use. There is one thread
pool per CLR; this thread pool is shared by all AppDomains controlled by that CLR.

When your application wants to perform an asynchronous operation,
you call some method that appends an entry into the thread pool’s queue.

The thread pool’s code will
extract entries from this queue and dispatch the entry to a thread pool thread.

However, when a thread pool thread has completed its task, the thread is
not destroyed; instead, the thread is returned to the thread pool, 
where it sits idle waiting to respond to another request.

If your application makes many requests of the thread pool, 
the thread pool will try to service all of the requests by using just this one thread. 
However, if your application is queuing up several requests faster 
than the thread pool thread can handle them, additional threads will be created.

//The method that queues a request to CLR's thread pool 
static Boolean QueueUserWorkItem(WaitCallback callBack);
static Boolean QueueUserWorkItem(WaitCallback callBack, Object state);

delegate void WaitCallback(Object state);

Example how to queue a request to the thread pool.


using System;
using System.Threading;

public static class Program 
{
    public static void Main() 
	{
        Console.WriteLine("Main thread: queuing an asynchronous operation");
		
        ThreadPool.QueueUserWorkItem(ComputeBoundOp, 5);
		
        Console.WriteLine("Main thread: Doing other work here...");
        Thread.Sleep(10000); // Simulating other work (10 seconds)
		
        Console.WriteLine("Hit <Enter> to end this program...");
        Console.ReadLine();
    }
	
    // This method's signature must match the WaitCallback delegate
    private static void ComputeBoundOp(Object state) 
	{
        // This method is executed by a thread pool thread
		
	    Console.WriteLine("In ComputeBoundOp: state={0}", state);
        Thread.Sleep(1000); // Simulates other work (1 second)
		
        // When this method returns, the thread goes back
        // to the pool and waits for another task
	}
}

37. What is execution context?

Some information which is passed to a child thread by a parent thread.
We should suppress this information to gain perfomance.

public static void Main() 
{
    // Put some data into the Main thread's logical call context
    CallContext.LogicalSetData("Name", "Jeffrey");
	
    // Initiate some work to be done by a thread pool thread
    // The thread pool thread can access the logical call context data
    ThreadPool.QueueUserWorkItem(state => Console.WriteLine("Name={0}", CallContext.LogicalGetData("Name")));
	
    // Now, suppress the flowing of the Main thread's execution context
    ExecutionContext.SuppressFlow();
	
	// Initiate some work to be done by a thread pool thread
    // The thread pool thread CANNOT access the logical call context data
    ThreadPool.QueueUserWorkItem(state => Console.WriteLine("Name={0}", CallContext.LogicalGetData("Name")));
	
    // Restore the flowing of the Main thread's execution context in case
    // it employs more thread pool threads in the future
    ExecutionContext.RestoreFlow();
	
    //...
    Console.ReadLine();
}


38. What is cooperative cancellation?

internal static class CancellationDemo 
{
    public static void Main() 
	{
        CancellationTokenSource cts = new CancellationTokenSource();
		
        // Pass the CancellationToken and the number-to-count-to into the operation
        ThreadPool.QueueUserWorkItem(o => Count(cts.Token, 1000));
		
        Console.WriteLine("Press <Enter> to cancel the operation.");
        Console.ReadLine();
		
		// If Count returned already, Cancel has no effect on it
        cts.Cancel();
		
        // Cancel returns immediately, and the method continues running here...
        Console.ReadLine();
	}
	
	private static void Count(
	    CancellationToken        token, 
		Int32                    countTo) 
    {
        for (Int32 count = 0; count <countTo; count++) 
		{
            if (token.IsCancellationRequested) 
			{
                Console.WriteLine("Count is cancelled");
                break; // Exit the loop to stop the operation
            }
			
            Console.WriteLine(count);
            Thread.Sleep(200);    // For demo, waste some time
        }
		
        Console.WriteLine("Count is done");
    }
}


39. How does task work?

ThreadPool.QueueUserWorkItem(ComputeBoundOp, 5); // Calling QueueUserWorkItem
new Task(ComputeBoundOp, 5).Start();             // Equivalent of preceding using Task
Task.Run(() => ComputeBoundOp(5));               // Another equivalent



40. How to wait for a task to finish execution?

private static Int32 Sum(Int32 n) 
{
   Int32 sum = 0;
   for (; n > 0; n--)
      checked { sum += n; } // if n is large, this will throw System.OverflowException
   return sum;
}

// Create a Task (it does not start running now)
Task<Int32> t = new Task<Int32>(n => Sum((Int32)n), 1000000000);

// You can start the task sometime later
t.Start();

// Optionally, you can explicitly wait for the task to complete
t.Wait(); // FYI: Overloads exist accepting timeout/CancellationToken

// You can get the result (the Result property internally calls Wait)
Console.WriteLine("The Sum is: " + t.Result); // An Int32 value

When a thread calls the Wait method, the system checks 
if the Task that the thread is waiting for has started executing. 

If it has, then the thread calling Wait will block
until the Task has completed running. 

But if the Task has not started executing yet, then
the system may (depending on the TaskScheduler) execute the Task by using the thread
that called Wait. 

If this happens, then the thread calling Wait does not block; it executes
the Task and returns immediately. This is good in that no thread has blocked, thereby
reducing resource usage (by not creating a thread to replace the blocked thread) while
improving performance (no time is spent to create a thread and there is no context switching).
But it can also be bad if, for example, the thread has taken a thread synchronization
lock before calling Wait and then the Task tries to take the same lock, resulting in a deadlocked
thread!


41. What happens if an exception has been thrown?

If the compute-bound task throws an unhandled exception, the exception will be swallowed,
stored in a collection, and the thread pool thread is allowed to return to the thread pool.
When the Wait method or the Result property is invoked, 
these members will throw a System.AggregateException object.

Wait for all threads to complete.

In addition to waiting for a single task, 
the Task class also offers two static methods that allow a
thread to wait on an array of Task objects. 
Task’s static WaitAny method blocks the calling thread
until any of the Task objects in the array have completed.

Similarly, the Task class has a static WaitAll method 
that blocks the calling thread until all the Task objects in the array have completed. 
The WaitAll method returns true if all the Task objects complete and false if a timeout occurs;

42. How to start a new task automatically when another completes?

Calling  task.Result causes the thread to wait until the task completes.
It can hurt perfomance. So to know when task completes we can use ContinueWith

// Create and start a Task, continue with another task
Task<Int32> t = Task.Run(() => Sum(CancellationToken.None, 10000));

// ContinueWith returns a Task but you usually don't care
Task cwt = t.ContinueWith(task => Console.WriteLine("The sum is: " + task.Result));

When an exception has occured in task we should process it:
- We can do it by applying ContinueWith method:

var task = Task.Factory.StartNew(() =>
{
    // Throws an exception 
    // (possibly from within another task spawned from within this task)
});

var failureTask = task.ContinueWith((t) =>
{
    // Flatten and loop (since there could have been multiple tasks)
    foreach (var ex in t.Exception.Flatten().InnerExceptions)
        Console.WriteLine(ex.Message);
}, TaskContinuationOptions.OnlyOnFaulted);

- We can specify ContinueWith and check for an exception there.

var task = Task.Factory.StartNew(() =>
{
    // Throws an exception 
    // (possibly from within another task spawned from within this task)
});

task.ContinueWith(task =>
{
    if (task.IsFaulted)
    {	
	    // handle errors
	}
	else 
	{
	    Console.WriteLine(task.Result.Headers);
    }
});

43. How to use child tasks?

Create a parent task that contains 3 child tasks

Task<Int32[]> parent = new Task<Int32[]>(() => 
{
    // Create an array for the results
    var results = new Int32[3]; 
	
    // This tasks creates and starts 3 child tasks
	var task1 = new Task(() => results[0] = Sum(10000), TaskCreationOptions.AttachedToParent);
	task1.Start();
    
	var task2 = new Task(() => results[1] = Sum(20000), TaskCreationOptions.AttachedToParent);
    task2.Start();
	
	var task3 = new Task(() => results[2] = Sum(30000), TaskCreationOptions.AttachedToParent);
	task3.Start();
	
    // Returns a reference to the array (even though the elements may not be initialized yet)
    return results;
});

Create a task that will be executed after the parent and all its child tasks.

// When the parent and its children have run to completion, display the results
var cwt = parent.ContinueWith(parentTask => Array.ForEach(parentTask.Result, Console.WriteLine));

// Start the parent Task so it can start its children
parent.Start();


44. What is TaskSchedulers?

A task scheduler makes sure that the work of a task is eventually executed. 
The default task scheduler is based on the .NET Framework 4 ThreadPool, 
which provides work-stealing for load-balancing, 
thread injection/retirement for maximum throughput, 
and overall good performance.


// Provides a task scheduler that ensures a maximum concurrency level while  
// running on top of the thread pool. 
public class LimitedConcurrencyLevelTaskScheduler : TaskScheduler
{
   // The list of tasks to be executed  
   private readonly LinkedList<Task> _tasks = new LinkedList<Task>(); // protected by lock(_tasks) 
   
   protected sealed override void QueueTask(Task task)
   {
       lock (_tasks)
       {
           _tasks.AddLast(task);
		   //notify thread pool to process thease threads
       }		   
   }
   
   protected sealed override bool TryExecuteTaskInline(Task task, bool taskWasPreviouslyQueued)
   {
       
   }
}

IOTaskScheduler This task scheduler queues tasks to the thread pool’s I/O threads instead
of its worker threads.

LimitedConcurrencyLevelTaskScheduler This task scheduler allows no more than n (a
constructor parameter) tasks to execute simultaneously.

OrderedTaskScheduler This task scheduler allows only one task to execute at a time. This
class is derived from LimitedConcurrencyLevelTaskScheduler and just passes 1 for n.


45. How to parallel foreach cycle?

- Paralleling of cycle 'for':

  // One thread performs all this work sequentially
  for (Int32 i = 0; i < 1000; i++) DoWork(i);
  
  can be paralleled as:
  
  // The thread pool’s threads process the work in parallel
  Parallel.For(0, 1000, i => DoWork(i));
  
- Parallelizing of cycle 'foreach':

  // One thread performs all this work sequentially
  foreach (var item in collection) DoWork(item);

  // The thread pool's threads process the work in parallel
  Parallel.ForEach(collection, item => DoWork(item));

- Methods:

  // One thread executes all the methods sequentially
  Method1();
  Method2();
  Method3();
  
  // The thread pool’s threads execute the methods in parallel
  Parallel.Invoke(
    () => Method1(),
    () => Method2(),
    () => Method3());
	
	
720	




